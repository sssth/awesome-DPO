# awesome-DPO
Papers related to Direct Preference Optimization（DPO）

1. DPO datasets
   - data format change
   - data clipping
   - data augmentation
2. train methods
3. loss function


### data format change
| Title | Method | Time | Motivation | Discription | Loss Function|
|:-------:|:-------:|:-------:|:-------:|:-------:|:-------:|
|KTO: Model Alignment as Prospect Theoretic Optimization|KTO|arXiv24|maximizes the utility of generations instead of maximizing the log-likelihood of preferences that are hard-to-get|![image](https://github.com/sssth/awesome-DPO/assets/105367602/f66fdb6c-6829-481e-af5d-d8a1c7dcef05)|![image](https://github.com/sssth/awesome-DPO/assets/105367602/cd22ad60-e8cf-4df4-a473-3ad20de4154e)|
